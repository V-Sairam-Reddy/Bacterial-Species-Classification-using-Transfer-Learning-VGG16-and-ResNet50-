{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreTrainedVGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb6QlbjPOFC7"
      },
      "source": [
        "# Importing Libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA58wRWCPhGu"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow.keras\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM-4XCJMOWUf"
      },
      "source": [
        "**Defining Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Eioe4nQ-jk"
      },
      "source": [
        "Batch_Size = 128\n",
        "Num_of_Iterations = 50\n",
        "Num_of_Classes = 5\n",
        "Num_of_Channels = 3\n",
        "image_dimn = [32,32]\n",
        "input_image_shape = [32,32,3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeIw2ZSGOfbi"
      },
      "source": [
        "# Loading Data\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV5r4noqa5WB",
        "outputId": "364a20c9-18c4-4859-edf5-13f60a40ee08"
      },
      "source": [
        "!7z x Trainingless.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 141541935 bytes (135 MiB)\n",
            "\n",
            "Extracting archive: Trainingless.zip\n",
            " 81% 4096 Open\b\b\b\b\b\b\b\b\b\b\b\b\b\b              \b\b\b\b\b\b\b\b\b\b\b\b\b\b--\n",
            "Path = Trainingless.zip\n",
            "Type = zip\n",
            "Physical Size = 141541935\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 16% 817 - Trainingless/C1/831.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 1511\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b 42% 2123 - Trainingless/Cdoop/586.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 2641 - Trainingless/C1/576.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 3123 - Trainingless/C1/380.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 3605 - Trainingless/Cdoop/153.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 4036\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b 87% 4372 - Trainingless/Lshit/1.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 4754 - Trainingless/Cdoop/240.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 5000\n",
            "Size:       140479878\n",
            "Compressed: 141541935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Wve3K8MVu0",
        "outputId": "119f3e46-e5d1-461a-eac3-8ed791ea47c7"
      },
      "source": [
        "!7z x Testless.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 39336323 bytes (38 MiB)\n",
            "\n",
            "Extracting archive: Testless.zip\n",
            "--\n",
            "Path = Testless.zip\n",
            "Type = zip\n",
            "Physical Size = 39336323\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 59% 744 - Testless/L/106.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 1250\n",
            "Size:       39116534\n",
            "Compressed: 39336323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PRwZplEPsuk",
        "outputId": "5aef925e-ce9a-4c51-f694-32e6bfd8972e"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=\"/content/Trainingless/\",\n",
        "    target_size=image_dimn,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=Batch_Size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB30Qd3fPy0P",
        "outputId": "7fed1946-7f54-4f97-a3ed-9e925155c1aa"
      },
      "source": [
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=\"/content/Testless/\",\n",
        "    target_size=image_dimn,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=Batch_Size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1250 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebGxwNVlOllc"
      },
      "source": [
        "# Building Model Using Transfer Learning (PreTrained VGG16)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmYjr2uuP3FQ"
      },
      "source": [
        "**Building and Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6viOPiDxzfq-",
        "outputId": "608de31e-d7ae-4687-f803-4bdb59770c51"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "#Using VGG16 as our Backbone\n",
        "base_model2 = VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_image_shape\n",
        ")\n",
        "\n",
        "x = base_model2.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "predictions = Dense(6, activation='softmax')(x)\n",
        "\n",
        "#Freezing Layers of VGG16\n",
        "model2 = Model(inputs=base_model2.input, outputs=predictions)\n",
        "for layer in base_model2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Compiling our Model\n",
        "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Model Check point to save our best Model\n",
        "checkpoint_filepath = '/content/drive/MyDrive/weights/'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#Training our Model\n",
        "hist = model2.fit(train_generator, validation_data=(test_generator), batch_size = Batch_Size, epochs = 50, shuffle=True, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "#Loading weights from the best model\n",
        "model2.load_weights(checkpoint_filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 15s 315ms/step - loss: 0.8820 - accuracy: 0.6526 - val_loss: 0.3933 - val_accuracy: 0.9008\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.1827 - accuracy: 0.9354 - val_loss: 0.2361 - val_accuracy: 0.9256\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 0.1139 - accuracy: 0.9586 - val_loss: 0.2335 - val_accuracy: 0.9184\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.1740 - val_accuracy: 0.9472\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0883 - accuracy: 0.9664 - val_loss: 0.3930 - val_accuracy: 0.8816\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.0671 - accuracy: 0.9758 - val_loss: 0.1988 - val_accuracy: 0.9416\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0653 - accuracy: 0.9738 - val_loss: 0.2014 - val_accuracy: 0.9456\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 0.0523 - accuracy: 0.9804 - val_loss: 0.2342 - val_accuracy: 0.9440\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.0478 - accuracy: 0.9818 - val_loss: 0.2045 - val_accuracy: 0.9480\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.2026 - val_accuracy: 0.9328\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.0485 - accuracy: 0.9810 - val_loss: 0.2208 - val_accuracy: 0.9424\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0722 - accuracy: 0.9756 - val_loss: 0.2011 - val_accuracy: 0.9400\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0393 - accuracy: 0.9850 - val_loss: 0.2194 - val_accuracy: 0.9376\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 10s 261ms/step - loss: 0.0527 - accuracy: 0.9798 - val_loss: 0.2366 - val_accuracy: 0.9400\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 0.0315 - accuracy: 0.9890 - val_loss: 0.2098 - val_accuracy: 0.9480\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0281 - accuracy: 0.9890 - val_loss: 0.2281 - val_accuracy: 0.9480\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.0323 - accuracy: 0.9876 - val_loss: 0.3066 - val_accuracy: 0.9248\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 10s 261ms/step - loss: 0.0293 - accuracy: 0.9876 - val_loss: 0.2503 - val_accuracy: 0.9440\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0227 - accuracy: 0.9904 - val_loss: 0.2339 - val_accuracy: 0.9456\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.0583 - accuracy: 0.9802 - val_loss: 0.1758 - val_accuracy: 0.9504\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 11s 271ms/step - loss: 0.0271 - accuracy: 0.9894 - val_loss: 0.2049 - val_accuracy: 0.9504\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.2162 - val_accuracy: 0.9496\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.2982 - val_accuracy: 0.9384\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 0.3217 - val_accuracy: 0.9328\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 0.0271 - accuracy: 0.9898 - val_loss: 0.4332 - val_accuracy: 0.9088\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 0.0595 - accuracy: 0.9780 - val_loss: 0.2560 - val_accuracy: 0.9360\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 0.0415 - accuracy: 0.9842 - val_loss: 0.2824 - val_accuracy: 0.9424\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 0.3523 - val_accuracy: 0.9312\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 11s 271ms/step - loss: 0.0236 - accuracy: 0.9902 - val_loss: 0.3008 - val_accuracy: 0.9400\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.2662 - val_accuracy: 0.9488\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 0.0195 - accuracy: 0.9914 - val_loss: 0.2640 - val_accuracy: 0.9480\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.0246 - accuracy: 0.9908 - val_loss: 0.2309 - val_accuracy: 0.9544\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.2669 - val_accuracy: 0.9488\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.3093 - val_accuracy: 0.9448\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.3618 - val_accuracy: 0.9336\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0151 - accuracy: 0.9936 - val_loss: 0.3500 - val_accuracy: 0.9360\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.5012 - val_accuracy: 0.9064\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 10s 266ms/step - loss: 0.0264 - accuracy: 0.9894 - val_loss: 0.3525 - val_accuracy: 0.9344\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.3790 - val_accuracy: 0.9344\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 10s 260ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.2635 - val_accuracy: 0.9424\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.3212 - val_accuracy: 0.9336\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0122 - accuracy: 0.9946 - val_loss: 0.3350 - val_accuracy: 0.9352\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.2762 - val_accuracy: 0.9520\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 10s 260ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.3961 - val_accuracy: 0.9296\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 10s 263ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.2742 - val_accuracy: 0.9512\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 10s 267ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.3009 - val_accuracy: 0.9488\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.3030 - val_accuracy: 0.9424\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.2936 - val_accuracy: 0.9384\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.3038 - val_accuracy: 0.9424\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.3249 - val_accuracy: 0.9424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbf587ddc10>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcfkd5VkQHaF"
      },
      "source": [
        "Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLe_GEoPAUd_",
        "outputId": "d6970777-d7c1-4216-c5ae-7adc3d863b44"
      },
      "source": [
        "scores = model2.evaluate(test_generator, verbose=1)\n",
        "\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', 100*scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 214ms/step - loss: 0.2309 - accuracy: 0.9544\n",
            "Test loss: 0.2309301495552063\n",
            "Test accuracy: 95.44000029563904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XJCUcpDQOPT"
      },
      "source": [
        "# Model Accuracy : 95.44 %"
      ]
    }
  ]
}